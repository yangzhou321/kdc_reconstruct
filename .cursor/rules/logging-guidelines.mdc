---
alwaysApply: true
---
Logging Guidelines for Kuavo Data Challenge

1. Executive Summary

This document outlines the mandatory logging strategy for the Kuavo Data Challenge software. Logging is critical for monitoring long-running training jobs, debugging complex ROS message synchronization, and ensuring safe robot deployment.

This strategy differentiates between Training (where metrics and hyperparameters are key), Data Processing (where data integrity and alignment are key), and Deployment (where safety, real-time control loop status, and hardware errors are key).

2. Logging Framework and Central Configuration

Framework: Python's standard logging module, augmented by kuavo_deploy.utils.logging_utils for colorized console output and file rotation.

Central Configuration Module: kuavo_deploy.utils.logging_utils.

Logger Instance Acquisition: Every Python module (.py file) that generates log messages MUST acquire its own logger instance at the top of the file using:

code
Python
download
content_copy
expand_less
import logging
logger = logging.getLogger(__name__)

This ensures the %(name)s field in log records captures the specific module path (e.g., kuavo_data.common.ros_handler).

Detailed Configuration:

Function: setup_logger(name, level=logging.INFO, log_file=None, save_to_file=False) (defined in kuavo_deploy/utils/logging_utils.py).

Root/Global Setup: Main entry points (train_policy.py, CvtRosbag2Lerobot.py, eval_kuavo.py) must initialize the logging system immediately after startup.

Handlers:

Console Handler (StreamHandler):

Purpose: Immediate operator feedback.

Formatter: Use ColoredFormatter for visual distinction (e.g., Red for ERROR, Green for INFO, Yellow for WARNING).

Format: "[%(asctime)s] [%(levelname)s] [%(name)s]: %(message)s"

File Handler (FileHandler):

Purpose: Persistent audit trail.

Path:

Training: Inside the Hydra output directory (outputs/YYYY-MM-DD/HH-MM-SS/training.log).

Deployment: logs/deploy/kuavo_eval_YYYYMMDD_HHMMSS.log.

Data Processing: logs/data_processing/convert.log.

3. Consistent Usage of Logging Levels

The coding AI MUST strictly adhere to the following guidelines:

logger.DEBUG:

Purpose: High-volume, low-level details useful only for deep debugging.

Usage Hooks:

ROS Message Sync: logger.debug(f"Syncing: Cam timestamp {t_cam} vs Joint timestamp {t_joint}, diff={diff}")

Tensor Shapes: logger.debug(f"Batch shape: {batch['observation.images.cam_high'].shape}")

Augmentation details: logger.debug(f"Applied random crop: {crop_params}")

logger.INFO:

Purpose: Key milestones in the workflow. Visible to the user by default.

Usage Hooks:

Startup: logger.info(f"Starting training for task: {cfg.task} with policy: {cfg.policy.name}")

Data Loading: logger.info(f"Loaded {len(dataset)} episodes. Total frames: {dataset.num_frames}")

Training Loop: logger.info(f"Epoch {epoch}: Loss = {loss.item():.4f}") (Use sparingly inside loops, prefer TensorBoard).

Robot State: logger.info("Robot connected successfully. Calibrating home position...")

logger.WARNING:

Purpose: Potential issues that don't stop execution but might affect quality.

Usage Hooks:

Data Drops: logger.warning(f"Dropped {dropped_frames} frames due to timestamp mismatch > {threshold}ms")

Hardware Limits: logger.warning(f"Action clipped: Command {cmd} exceeded limit {limit}")

Missing Sensors: logger.warning("Depth camera topic not found. Proceeding with RGB only.")

logger.ERROR:

Purpose: Operation failed, but the process might recover or needs to shut down gracefully.

Usage Hooks:

ROS Communication: logger.error("Lost connection to ROS master. Attempting reconnect...")

IO Failures: logger.error(f"Failed to save checkpoint to {path}", exc_info=True)

Safety Trigger: logger.error("Joint velocity limit exceeded! Triggering emergency stop.")

logger.CRITICAL:

Purpose: Immediate, unrecoverable failure. The script will likely exit immediately after.

Usage Hooks:

Hardware Fault: logger.critical("Robot hardware fault detected (Error Code: X). Shutting down.")

Config Error: logger.critical("Invalid configuration: 'policy_type' missing. Cannot proceed.")

4. Special Considerations for this Project

Multi-Processing (ROS Handler):

The ROSHandler runs in a separate process. It must not share logger instances with the main process directly. Instead, it should log to its own file or use a QueueListener if unified logging is required (though separate files are often simpler for ROS nodes).

Guideline: In ros_handler.py, initialize a fresh logger inside the run() method.

Training Metrics (TensorBoard/WandB):

Do not rely solely on logging for numerical metrics (loss, reward). Use torch.utils.tensorboard or wandb for plotting.

Guideline: Log summary stats to INFO (e.g., "End of Epoch 10: Mean Loss 0.05") but stream raw values to TensorBoard.

Safety Logs (Deployment):

In kuavo_deploy, safety is paramount. Any intervention by the KeyListener (e.g., user pressed Esc) or SafetyFilter (clamping actions) MUST be logged at WARNING or ERROR level to provide an audit trail of why the robot behaved a certain way.

5. General Principles

Context is King: Always include episode_id, epoch, or step where applicable.

Performance: Avoid f-strings with expensive function calls in debug logs if the level is set to INFO.

Bad: logger.debug(f"Stats: {calculate_heavy_stats(data)}")

Good: if logger.isEnabledFor(logging.DEBUG): logger.debug(f"Stats: {calculate_heavy_stats(data)}")

No Sensitive Data: Do not log raw image tensors or massive arrays to the console. Log their shapes or stats (min/max/mean) instead.