hydra: # Hydra 配置文件保存目录，仅供参数检查使用
  run:
    dir: ./outputs/train_hydra_save/singlerun/${now:%Y%m%d_%H%M%S}  # 单次运行目录
  sweep:
    dir: ./outputs/train_hydra_save/multirun/${now:%Y%m%d_%H%M%S}  # sweep并行时的根目录
    subdir: ${hydra:job.override_dirname}


task: "your_task_name"  # 自定义任务名称，如果不使用本地数据想使用huggingface官方数据，请指定，例如pusht，aloha_sim_insertion_human等
method: "your_method_name"  # 自定义方法名称
timestamp: ${now:%Y%m%d_%H%M%S}  # 自动获取的运行时时间戳
# 训练时模型参数的保存目录在outputs/train/<task>/<method>/<timestamp>中
repoid: "lerobot/${task}"  # lerobot新版本需指定这个，仅供参考，设置了即可
root: "/your/path/to/your/lerobotdata/lerobot"  # 你的本地转换好的lerobot数据的目录
# root: null  # 如果不使用本地数据想使用huggingface官方数据，请在task中指定，例如pusht，aloha_sim_insertion_human，此处就设置为null空
# 将去云端调用下载数据集

# 训练相关配置
training:
    output_directory: "outputs/train/${task}/${method}"  # 模型参数保存路径，默认这个结构，不要改动
    seed: 2025  # 数据增广、训练模型的随机种子，便于复现
    max_epoch: 1000  # 最大训练轮次，用于控制学习率调整器，与下述max_training_step相关

    save_freq_epoch: 10  # 模型参数保存频率，每10个epoch保存一次
    log_freq: 1  # 进度条刷新频率，每1个迭代step
    device: "cuda" # 训练设备，目前只支持单卡，多卡请使用CUDA_VISIBLE_DEVICES=6指定环境变量后使用，cuda:6这种类似的可能会出错
    accumulation_steps: 1  # 梯度累积步数，自定义
    ema_power: 0.75  # 如果使用ema移动指数平均方法可使用这个参数，目前测试使用ema会掉性能，所以代码中不再支持

    batch_size: 64  # 批次大小
    num_workers: 8  # dataloader的num_workers
    drop_last: False  # 是否丢弃最后一个不完整的batch

    # 最大训练步数，用于控制学习率调整器，如果指定了 `max_training_step`，则它将优先生效，否则，该值将根据上述的 `max_epoch` 自动确定。
    # `max_epoch` 和 `max_training_step` 不会同时生效。
    max_training_step: null  

    # resume training，断点续训
    resume: False
    resume_timestamp: "run_20250826_181254"  # 若开启，将从outputs/train/<task>/<method>/<resume_timestamp>中加载最后一个epoch参数续训

    scheduler_name: cosine  # 学习率调整器名称，仅在policy config中不包含该调度器时生效，否则会使用policy自带的调整器，相关参数也会在下方policy里
    scheduler_warmup_steps: 500  # 学习率预热warm up步数


    # 数据增广相关的配置
    RGB_Augmenter:
      enable: True
      max_num_transforms: 1
      random_order: True
      tfs:
        notransform:
          weight: 2.0  # 占比权重
          type: "Identity"
          kwargs: {}
        brightness:
          weight: 1.0
          type: "ColorJitter"
          kwargs: {"brightness": [0.5, 1.5]}
        contrast:
          weight: 1.0
          type: "ColorJitter"
          kwargs: {"contrast": [0.5, 1.5]}
        saturation:
          weight: 1.0
          type: "ColorJitter"
          kwargs: {"saturation": [0.5, 1.5]}
        hue:
          weight: 1.0
          type: "ColorJitter"
          kwargs: {"hue": [-0.05, 0.05]}
        sharpness:
          weight: 1.0
          type: "SharpnessJitter"
          kwargs: {"sharpness": [0.5, 1.5]}
        random_mask:
          weight: 1.0
          type: RandomMask
          kwargs:
            mask_size: [0.1, 0.1]   # h_ratio, w_ratio
        random_border_cutout:
          weight: 1.0
          type: RandomBorderCutout
          kwargs:
            cut_ratio: 0.15
        gaussian_noise:
          weight: 1.0
          type: GaussianNoise
          kwargs:
            mean: 0.0
            std: 0.05
        gamma_correction:
          weight: 1.0
          type: GammaCorrection
          kwargs:
            gamma: [0.5, 2.0]

policy_name: act  # 策略类型，支持diffusion和act

# 策略相关
policy:
    _target_: lerobot.policies.act.configuration_act.ACTConfig  # 用于实例化
    n_obs_steps: 1  # 观测步数
    chunk_size: 100  # 动作块大小
    n_action_steps: 100  # 动作步数

    use_amp: False  # 是否使用混合精度训练

    # 模型超参数相关调整
    vision_backbone: resnet18
    pretrained_backbone_weights: ResNet18_Weights.IMAGENET1K_V1
    replace_final_stride_with_dilation: False
    # Transformer layers.
    pre_norm: False
    dim_model: 512
    n_heads: 8
    dim_feedforward: 3200
    feedforward_activation: relu
    n_encoder_layers: 4
    # Note: Although the original ACT implementation has 7 for `n_decoder_layers`, there is a bug in the code
    # that means only the first layer is used. Here we match the original implementation by setting this to 1.
    # See this issue https://github.com/tonyzhaozh/act/issues/25#issue-2258740521.
    n_decoder_layers: 1
    # VAE.
    use_vae: True
    latent_dim: 32
    n_vae_encoder_layers: 4

    # Inference.
    # Note: the value used in ACT when temporal ensembling is enabled is 0.01.
    temporal_ensemble_coeff: null

    # Training and loss computation.
    dropout: 0.1
    kl_weight: 10.0

    # Training preset
    optimizer_lr: 1e-5
    optimizer_weight_decay: 1e-4
    optimizer_lr_backbone: 1e-5
