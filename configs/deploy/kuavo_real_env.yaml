hydra:  # Hydra 配置文件保存目录，仅供参数检查使用
  run:
    dir: ./outputs/kuavo_real_deploy_hydra_save/singlerun/${now:%Y%m%d_%H%M%S}  # 单次运行目录
  sweep:
    dir: ./outputs/kuavo_real_deploy_hydra_save/multirun/${now:%Y%m%d_%H%M%S}  # sweep并行时的根目录
    subdir: ${hydra:job.override_dirname}


# env config，真机运行配置文件
real: true # 是否使用真实机器人，default=false

only_arm: true  # 默认true, 是否只使用手臂数据, 目前的模仿学习只用于手臂数据，选择true会自动屏蔽足关节数据
eef_type: qiangnao  # 末端执行器类型: 仿真选择：rq2f85, 真机可选：leju_claw, qiangnao
control_mode: joint # or eef（暂未支持）
which_arm: right  # 需要哪一只手臂的数据，可选: left, right, both，注意这会同时选择对应手臂的相机，已默认包含头部相机
head_init: null # 机器人头部初始位置，default=None

# input_images：输入图像，可选"head_cam_h",'depth_h','wrist_cam_l','depth_l','wrist_cam_r','depth_r'
# (每个都是可选，需要与你的机器人配置、训练模型一致)
# 通常：cameras = [{"left":['head_cam_h','wrist_cam_l'],
#                 "right":['head_cam_h','wrist_cam_r'],
#                 "both":['head_cam_h','wrist_cam_l','wrist_cam_r']
#                 },
#                 {"left":['head_cam_h','depth_h','wrist_cam_l','depth_l'],
#                 "right":['head_cam_h','depth_h','wrist_cam_r','depth_r'],
#                 "both":['head_cam_h','depth_h','wrist_cam_l','depth_l','wrist_cam_r','depth_r']
#                 }][int(self.use_depth)][self.which_arm]
input_images: ["head_cam_h", "wrist_cam_r"]  # 目前本分支只有diffusion policy支持了深度，ACT policy暂不支持深度图像，但在dev分支中已经支持
depth_range: [0, 1000]  # 深度图的裁剪范围，单位：毫米，没有深度图时不起作用
image_size: [480, 848] # 图像大小（高，宽），default=(480, 640)
ros_rate: 10  # 推理频率，单位Hz

# 以下环境配置为不建议改动配置

# qiangnao_dof_needed是强脑手需要的自由度数目。强脑灵巧手有6个自由度。标准握拳状态[100] * 6, 张开状态[0] * 6。
# 1: 不需要精细操作或者多指协同操作时，通常为设置为1，表示只需要第一个关节作为开合依据,此时需要用[0, 100, 0, 0, 0, 0]表示张开状态, [100] * 6表示握拳状态。
# 2(暂未测试): 或者设置为2，目前的手柄遥操作只有两个自由度。0,2,3,4,5自由度绑定为1个自由度。
# 6(暂未测试): 如果脱离手柄使用手指灵巧操作，可以设置为6，表示需要所有6个自由度。
qiangnao_dof_needed: 1   # default=1

# leju_claw_dof_needed是夹爪需要的自由度数目。夹爪有1个自由度。仿真中，标准夹紧状态[0], 张开状态[-100]。
leju_claw_dof_needed: 1 # default=1

# rq2f85_dof_needed是夹抓rq2f85需要的自由度数目。
rq2f85_dof_needed: 1 # default=1

arm_init: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0] # 手臂初始位置，default=0
# arm_min: [-180, -40, -90, -150, -90, -75, -40, -180, -40, -90, -150, -90, -75, -40] # 手臂最小角度
# arm_max: [90, 120, 90, 0, 90, 40, 40, 90, 120, 90, 0, 90, 40, 40] # 手臂最大角度

arm_min: [-180,-180,-180,-180,-180,-180,-180,-180,-180,-180,-180,-180,-180,-180]
arm_max: [180,180,180,180,180,180,180,180,180,180,180,180,180,180]

eef_min: [0] # 末端执行器最小角度
eef_max: [1] # 末端执行器最大角度

is_binary: false # 是否使用二值化夹爪，灵巧手，default=false



# inference config，模型推理配置的修改
go_bag_path: /your_bag_path  # 推理时需要提供bag包的完整路径，如：到达预抓取姿态等，可直接拷贝一个训练用rosbag控制

policy_type: "diffusion"  # 策略名字，支持diffusion，act等
use_delta: false  # 是否使用增量动作，default=false（暂未支持）
eval_episodes: 1  # 测试回合数，真机默认为1
seed: 42  # 随机种子，真机中仅模型状态可固定，
start_seed: 42  # 回合开始时的随机种子，真机中仅模型状态可固定
device: "cuda"  # or "cpu"
task: "your_task"
method: "your_method"
timestamp: "your_timestamp"
epoch: 10  # 使用训练保存的哪一个epoch。注意：代码将在outputs/<task>/<method>/run_<timestamp>/epoch10中load policy的模型参数
max_episode_steps: 500  # 最大回合步数，超过自动结束
env_name: Kuavo-Real  # kuavo真机环境名称

